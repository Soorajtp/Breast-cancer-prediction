# -*- coding: utf-8 -*-
"""app.py.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZRTud9IiPrI30SrHMK-dJJQkRi1oh-hW
"""

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from rev03_2025aa05652_ml2 import (
    load_data,
    split_and_scale,
    get_model,
    train_and_evaluate,
    predict_on_new_data
)

st.set_page_config(page_title="Breast Cancer Prediction", layout="wide")
st.title("Breast Cancer Prediction App")

st.write("""
This app trains and evaluates multiple machine learning models on the Breast Cancer Wisconsin dataset,
shows performance metrics and visualizations, and allows predictions on new data.
""")

# -----------------------------
# Load data
# -----------------------------
df, X, y = load_data()

st.subheader("Dataset Preview")
st.dataframe(df.head())

# Download dataset
st.subheader("Download Dataset")
dataset_csv = df.to_csv(index=False).encode("utf-8")
st.download_button(
    label="Download Dataset CSV",
    data=dataset_csv,
    file_name="Breast_Cancer_Wisconsin.csv",
    mime="text/csv",
)

# -----------------------------
# Sidebar controls
# -----------------------------
st.sidebar.header("Model Settings")

model_name = st.sidebar.selectbox(
    "Choose a model",
    ["Logistic Regression", "Decision Tree", "KNN", "Naive Bayes", "Random Forest", "XGBoost"]
)

k_value = st.sidebar.slider("K (for KNN)", 1, 15, 5)
n_estimators = st.sidebar.slider("Number of trees (for Random Forest)", 50, 300, 100, step=50)

# -----------------------------
# Prepare data once
# -----------------------------
X_train_scaled, X_test_scaled, y_train, y_test, scaler = split_and_scale(X, y)

# -----------------------------
# Train & Evaluate
# -----------------------------
if st.button("Train & Evaluate"):
    if model_name == "KNN":
        model = get_model(model_name, k=k_value)
    elif model_name == "Random Forest":
        model = get_model(model_name, n_estimators=n_estimators)
    else:
        model = get_model(model_name)

    metrics, y_pred, y_prob = train_and_evaluate(
        model, X_train_scaled, X_test_scaled, y_train, y_test
    )

    st.subheader("Model Performance Metrics")
    metrics_df = pd.DataFrame([metrics])
    st.table(metrics_df)

    # Download metrics
    st.subheader("Download Metrics")
    metrics_csv = metrics_df.to_csv(index=False).encode("utf-8")
    st.download_button(
        label="Download Metrics CSV",
        data=metrics_csv,
        file_name=f"{model_name}_metrics.csv",
        mime="text/csv",
    )

    # Bar chart of metrics
    st.subheader("Metrics Bar Chart")
    fig, ax = plt.subplots(figsize=(3,1.5))
    ax.bar(metrics.keys(), metrics.values(),width=0.4)
    ax.set_ylim(0, 1)
    ax.set_ylabel("Score",fontsize=5)
    ax.set_title(f"Performance Metrics - {model_name}",fontsize=5)
    ax.tick_params(axis="both",labelsize=4)
    st.pyplot(fig)

    # Confusion Matrix
    from sklearn.metrics import confusion_matrix

    st.subheader("Confusion Matrix")
    cm = confusion_matrix(y_test, y_pred)

    fig2, ax2 = plt.subplots(figsize=(1,1))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax2,annot_kws={"size":4},cbar=False,linewidths=.5,linecolor="black")
    ax2.set_xlabel("Predicted",fontsize=3)
    ax2.set_ylabel("Actual",fontsize=3)
    ax2.set_title(f"Confusion Matrix - {model_name}",fontsize=3)
    ax2.tick_params(axis="both",labelsize=3)
    
    st.pyplot(fig2)

    # -----------------------------
    # Feature Importance (RF / XGBoost)
    # -----------------------------
    if model_name in ["Random Forest", "XGBoost"]:
        st.subheader("Feature Importance")

        importances = model.feature_importances_
        feature_names = X.columns

        fi_df = pd.DataFrame({
            "Feature": feature_names,
            "Importance": importances
        }).sort_values(by="Importance", ascending=False).head(15)

        fig_fi, ax_fi = plt.subplots(figsize=(5,3))
        ax_fi.barh(fi_df["Feature"], fi_df["Importance"])
        ax_fi.invert_yaxis()
        ax_fi.set_title(f"Top 15 Feature Importances - {model_name}",fontsize=5)
        ax_fi.set_xlabel("Importance",fontsize=5)
        ax_fi.tick_params(axis="both",labelsize=4)
        st.pyplot(fig_fi)

    # -----------------------------
    # Logistic Regression Coefficients
    # -----------------------------
    if model_name == "Logistic Regression":
        st.subheader("Logistic Regression Coefficients")

        coefs = model.coef_[0]
        feature_names = X.columns

        coef_df = pd.DataFrame({
            "Feature": feature_names,
            "Coefficient": coefs
        }).sort_values(by="Coefficient", key=abs, ascending=False).head(15)

        fig_coef, ax_coef = plt.subplots(figsize=(3,1.5))
        ax_coef.barh(coef_df["Feature"], coef_df["Coefficient"])
        ax_coef.invert_yaxis()
        ax_coef.set_title("Top 15 Logistic Regression Coefficients (by magnitude)",fontsize=5)
        ax_coef.set_xlabel("Coefficient Value",fontsize=5)
        ax_coef.tick_params(axis="both",labelsize=4)
        st.pyplot(fig_coef)

# -----------------------------
# Hyperparameter Analysis
# -----------------------------
st.header("Hyperparameter Analysis")

# KNN: Accuracy vs K
st.subheader("KNN: Accuracy vs K")
k_range = list(range(1, 16))
acc_scores = []

for k in k_range:
    model_knn = get_model("KNN", k=k)
    metrics_k, _, _ = train_and_evaluate(model_knn, X_train_scaled, X_test_scaled, y_train, y_test)
    acc_scores.append(metrics_k["accuracy"])

fig_k, ax_k = plt.subplots(figsize=(3,1.5))
ax_k.plot(k_range, acc_scores, marker="o",markersize=2.5)
ax_k.set_xlabel("K (Number of Neighbors)",fontsize=5)
ax_k.set_ylabel("Accuracy",fontsize=5)
ax_k.set_title("KNN: Accuracy vs K",fontsize=5)
ax_k.tick_params(axis="both",labelsize=4)
st.pyplot(fig_k)

# Random Forest: Accuracy vs Number of Trees
st.subheader("Random Forest: Accuracy vs Number of Trees")
tree_counts = [50, 100, 150, 200, 250, 300]
rf_acc_scores = []

for n_trees in tree_counts:
    model_rf = get_model("Random Forest", n_estimators=n_trees)
    metrics_rf, _, _ = train_and_evaluate(model_rf, X_train_scaled, X_test_scaled, y_train, y_test)
    rf_acc_scores.append(metrics_rf["accuracy"])

fig_rf, ax_rf = plt.subplots(figsize=(5,2.5))
ax_rf.plot(tree_counts, rf_acc_scores, marker="o",markersize=2.5)
ax_rf.set_xlabel("Number of Trees",fontsize=5)
ax_rf.set_ylabel("Accuracy",fontsize=5)
ax_rf.set_title("Random Forest: Accuracy vs Number of Trees",fontsize=5)
ax_rf.tick_params(axis="both",labelsize=4)
st.pyplot(fig_rf)

# -----------------------------
# CSV Upload for Batch Prediction
# -----------------------------
st.header("Predict on New Data (Upload CSV)")
uploaded_file = st.file_uploader("Upload a CSV file with the same features", type=["csv"])

if uploaded_file is not None:
    new_df = pd.read_csv(uploaded_file)
    st.write("Uploaded data preview:")
    st.dataframe(new_df.head())

    # Train a default model for prediction demo (Random Forest)
    model = get_model("Random Forest")
    model.fit(X_train_scaled, y_train)

    preds = predict_on_new_data(model, scaler, new_df)

    result_df = new_df.copy()
    result_df["Prediction"] = pd.Series(preds).map({0: "Benign", 1: "Malignant"})

    st.subheader("Prediction Results")
    st.dataframe(result_df)

    # Download predictions
    st.subheader("Download Predictions")
    pred_csv = result_df.to_csv(index=False).encode("utf-8")
    st.download_button(
        label="Download Predictions CSV",
        data=pred_csv,
        file_name="predictions.csv",
        mime="text/csv",
    )

# -----------------------------
# Manual Input Prediction (Single Sample)
# -----------------------------
st.header("Manual Input Prediction (Single Sample)")

feature_names = X.columns.tolist()
input_data = {}

for feature in feature_names:
    min_val = float(X[feature].min())
    max_val = float(X[feature].max())
    mean_val = float(X[feature].mean())

    input_data[feature] = st.slider(
        label=feature,
        min_value=min_val,
        max_value=max_val,
        value=mean_val
    )

input_df = pd.DataFrame([input_data])

if st.button("Predict from Manual Input"):
    model = get_model("Random Forest")
    model.fit(X_train_scaled, y_train)

    pred = predict_on_new_data(model, scaler, input_df)

    st.subheader("Prediction Result")
    if int(pred[0]) == 1:
        st.error("Malignant (Cancer Detected)")
    else:
        st.success("Benign (No Cancer Detected)")