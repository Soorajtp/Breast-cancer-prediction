# -*- coding: utf-8 -*-
"""Rev03- 2025aa05652_ML2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lx6sIQ52aB2yXDdV6eHuGg2CV0njdcmv

Breast Cancer Wisconsin (Diagnostic) Data Set-Multi variate-30 features
Predict whether the cancer is benign or malignant-https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic
Dataset info-Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at http://www.cs.wisc.edu/~street/images/
"""

import numpy as np
import pandas as pd

def load_data(csv_path=None):
    # =========================
    # Not necessary for Streamlit (original code path in my google drive)
    # =========================
    url = "/content/drive/MyDrive/ML2/Breast Cancer Wisconsin.csv"
    data="data.csv"
    if csv_path is None:
        df = pd.read_csv(data)
    else:
        df = pd.read_csv(csv_path)

    df = df.drop(columns=["id", "Unnamed: 32"], errors="ignore")
    df["diagnosis"] = df["diagnosis"].map({"M": 1, "B": 0})

    X = df.drop("diagnosis", axis=1)
    y = df["diagnosis"]
    return df, X, y

# =========================
#  Outlier check using Z-score
# =========================
from scipy import stats

def count_outliers_zscore(X, threshold=3):
    z_scores = np.abs(stats.zscore(X))
    outlier_rows = np.where(z_scores > threshold)
    return len(set(outlier_rows[0]))

# =========================
# verify result
# =========================
def debug_block_2():
    df, X, y = load_data()  # uses your Drive-based path
    outliers = count_outliers_zscore(X)
    print("Number of rows with any outlier (Z-score > 3):", outliers)

# =========================
# verify result
# =========================
#if __name__ == "__main__":
    #debug_block_2()

# =========================
# Train-test split + StandardScaler
# =========================
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

def split_and_scale(X, y, test_size=0.2, random_state=42):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    return X_train_scaled, X_test_scaled, y_train, y_test, scaler


# =========================
# verify result
# =========================
def debug_block_3():
    df, X, y = load_data()  # uses your Drive-based path
    X_train_scaled, X_test_scaled, y_train, y_test, scaler = split_and_scale(X, y)

    print("Train scaled shape:", X_train_scaled.shape)
    print("Test scaled shape :", X_test_scaled.shape)
    print("y_train distribution:")
    print(y_train.value_counts())
    print("y_test distribution:")
    print(y_test.value_counts())


# =========================
# verify result
# =========================
#if __name__ == "__main__":
   # debug_block_3()

# =========================
# All  Models
# =========================
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

def get_model(name, k=5, n_estimators=100):
    if name == "Logistic Regression":
        return LogisticRegression(max_iter=900)
    elif name == "Decision Tree":
        return DecisionTreeClassifier(random_state=42)
    elif name == "KNN":
        return KNeighborsClassifier(n_neighbors=k)
    elif name == "Naive Bayes":
        return GaussianNB()
    elif name == "Random Forest":
        return RandomForestClassifier(n_estimators=n_estimators, random_state=42)
    elif name == "XGBoost":
        return XGBClassifier(eval_metric="logloss", random_state=42)
    else:
        raise ValueError("Unknown model name")


# =========================
# verify results
# =========================
def debug_block_4():
    names = [
        "Logistic Regression",
        "Decision Tree",
        "KNN",
        "Naive Bayes",
        "Random Forest",
        "XGBoost"
    ]
    for name in names:
        model = get_model(name)
        print(f"{name} -> {model}")


# =========================
# verify result
# =========================
#if __name__ == "__main__":
    #debug_block_4()

# =========================
# Train + Evaluate
# =========================
from sklearn.metrics import (
    accuracy_score, roc_auc_score, precision_score,
    recall_score, f1_score, matthews_corrcoef
)

def train_and_evaluate(model, X_train_scaled, X_test_scaled, y_train, y_test):
    model.fit(X_train_scaled, y_train)

    y_pred = model.predict(X_test_scaled)

    if hasattr(model, "predict_proba"):
        y_prob = model.predict_proba(X_test_scaled)[:, 1]
    else:
        y_prob = None

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    mcc = matthews_corrcoef(y_test, y_pred)

    if y_prob is not None:
        auc = roc_auc_score(y_test, y_prob)
    else:
        auc = np.nan

    metrics = {
        "accuracy": acc,
        "auc": auc,
        "precision": prec,
        "recall": rec,
        "f1": f1,
        "mcc": mcc
    }

    return metrics, y_pred, y_prob


# =========================
# verify result
# =========================
def debug_block_5():
    # Uses your Drive-based load_data()
    df, X, y = load_data()
    X_train_scaled, X_test_scaled, y_train, y_test, scaler = split_and_scale(X, y)

    # Test with one model first (Logistic Regression)
    model = get_model("Logistic Regression")

    metrics, y_pred, y_prob = train_and_evaluate(
        model, X_train_scaled, X_test_scaled, y_train, y_test
    )

    print("=== Model: Logistic Regression ===")
    print("Accuracy :", metrics["accuracy"])
    print("AUC      :", metrics["auc"])
    print("Precision:", metrics["precision"])
    print("Recall   :", metrics["recall"])
    print("F1-score :", metrics["f1"])
    print("MCC      :", metrics["mcc"])
    print("=================================")


# =========================
# verify result
# =========================
#if __name__ == "__main__":
    #debug_block_5()

# =========================
# verify result
# =========================
def debug_block_6():
    # Load data
    df, X, y = load_data()

    # Split and scale
    X_train_scaled, X_test_scaled, y_train, y_test, scaler = split_and_scale(X, y)

    model_names = [
        "Logistic Regression",
        "Decision Tree",
        "KNN",
        "Naive Bayes",
        "Random Forest",
        "XGBoost"
    ]

    all_results = []

    for name in model_names:
        model = get_model(name)
        metrics, y_pred, y_prob = train_and_evaluate(
            model, X_train_scaled, X_test_scaled, y_train, y_test
        )

        print("\n=== Model:", name, "===")
        print("Accuracy :", metrics["accuracy"])
        print("AUC      :", metrics["auc"])
        print("Precision:", metrics["precision"])
        print("Recall   :", metrics["recall"])
        print("F1-score :", metrics["f1"])
        print("MCC      :", metrics["mcc"])

        all_results.append({"Model": name, **metrics})

    results_df = pd.DataFrame(all_results)

    print("\n=== Summary Table ===")
    print(results_df)


# =========================
# verify block
# =========================
#if __name__ == "__main__":
   # debug_block_6()

# =========================
# Predict
# =========================
def predict_on_new_data(model, scaler, X_new_df):
    X_new_scaled = scaler.transform(X_new_df)
    preds = model.predict(X_new_scaled)
    return preds


# =========================
# verify result
# =========================
def debug_block_7():
    # Load data
    df, X, y = load_data()

    # Split and scale
    X_train_scaled, X_test_scaled, y_train, y_test, scaler = split_and_scale(X, y)

    # Train a model
    model = get_model("Random Forest")
    metrics, y_pred, y_prob = train_and_evaluate(
        model, X_train_scaled, X_test_scaled, y_train, y_test
    )

    # Take a few samples as "new/unseen"
    X_new = X.head(5)

    preds = predict_on_new_data(model, scaler, X_new)

    print("=== Predict on new data (first 5 rows) ===")
    print("Predictions (0 = Benign, 1 = Malignant):")
    print(preds)


# =========================
#  verify output
# =========================
#if __name__ == "__main__":
    #debug_block_7()